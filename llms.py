# -*- coding: utf-8 -*-
"""LLMs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EvbWzT3pdN6nCQBrD4SR_ZzBshnwxZpF
"""

!pip install langchain-huggingface
!pip install huggingface_hub
!pip install transformers
!pip install accelerate
!pip install bitsandbytes
!pip install langchain

from langchain_huggingface import HuggingFaceEndpoint

from google.colab import userdata
sec_key = userdata.get('HUGGINGFACE_HUB_API_TOKEN')

import os
os.environ["HUGGINGFACE_HUB_API_TOKEN"] = sec_key

repo_id = "mistralai/Mistral-7B-Instruct-v0.3"
llm = HuggingFaceEndpoint(repo_id=repo_id,temperature=0.7)

llm

llm.invoke("Tell me something about farming")

from langchain import PromptTemplate, LLMChain
question = "Your question"

template = """Question: {question}

Answer: Customize the prompt."""

prompt = PromptTemplate(template=template, input_variables=["question"])

llm_chain = LLMChain(llm=llm, prompt=prompt)
# print(llm_chain.run(question))
print(llm_chain.invoke(question))